{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d39306cb-55ff-454f-a703-c391e0fb7ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#!pip install xgboost\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "#!pip install shap\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e0bfeb8-17dc-460e-a046-9a858b8514cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>11.0656</td>\n",
       "      <td>7.7798</td>\n",
       "      <td>12.9536</td>\n",
       "      <td>9.4292</td>\n",
       "      <td>11.4327</td>\n",
       "      <td>-2.3805</td>\n",
       "      <td>5.8493</td>\n",
       "      <td>18.2675</td>\n",
       "      <td>2.1337</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.1556</td>\n",
       "      <td>11.8495</td>\n",
       "      <td>-1.4300</td>\n",
       "      <td>2.4508</td>\n",
       "      <td>13.7112</td>\n",
       "      <td>2.4669</td>\n",
       "      <td>4.3654</td>\n",
       "      <td>10.7200</td>\n",
       "      <td>15.4722</td>\n",
       "      <td>-8.7197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>8.5304</td>\n",
       "      <td>1.2543</td>\n",
       "      <td>11.3047</td>\n",
       "      <td>5.1858</td>\n",
       "      <td>9.1974</td>\n",
       "      <td>-4.0117</td>\n",
       "      <td>6.0196</td>\n",
       "      <td>18.6316</td>\n",
       "      <td>-4.4131</td>\n",
       "      <td>...</td>\n",
       "      <td>10.6165</td>\n",
       "      <td>8.8349</td>\n",
       "      <td>0.9403</td>\n",
       "      <td>10.1282</td>\n",
       "      <td>15.5765</td>\n",
       "      <td>0.4773</td>\n",
       "      <td>-1.4852</td>\n",
       "      <td>9.8714</td>\n",
       "      <td>19.1293</td>\n",
       "      <td>-20.9760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>5.4827</td>\n",
       "      <td>-10.3581</td>\n",
       "      <td>10.1407</td>\n",
       "      <td>7.0479</td>\n",
       "      <td>10.2628</td>\n",
       "      <td>9.8052</td>\n",
       "      <td>4.8950</td>\n",
       "      <td>20.2537</td>\n",
       "      <td>1.5233</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7484</td>\n",
       "      <td>10.9935</td>\n",
       "      <td>1.9803</td>\n",
       "      <td>2.1800</td>\n",
       "      <td>12.9813</td>\n",
       "      <td>2.1281</td>\n",
       "      <td>-7.1086</td>\n",
       "      <td>7.0618</td>\n",
       "      <td>19.8956</td>\n",
       "      <td>-23.1794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>8.5374</td>\n",
       "      <td>-1.3222</td>\n",
       "      <td>12.0220</td>\n",
       "      <td>6.5749</td>\n",
       "      <td>8.8458</td>\n",
       "      <td>3.1744</td>\n",
       "      <td>4.9397</td>\n",
       "      <td>20.5660</td>\n",
       "      <td>3.3755</td>\n",
       "      <td>...</td>\n",
       "      <td>9.5702</td>\n",
       "      <td>9.0766</td>\n",
       "      <td>1.6580</td>\n",
       "      <td>3.5813</td>\n",
       "      <td>15.1874</td>\n",
       "      <td>3.1656</td>\n",
       "      <td>3.9567</td>\n",
       "      <td>9.2295</td>\n",
       "      <td>13.0168</td>\n",
       "      <td>-4.2108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>11.7058</td>\n",
       "      <td>-0.1327</td>\n",
       "      <td>14.1295</td>\n",
       "      <td>7.7506</td>\n",
       "      <td>9.1035</td>\n",
       "      <td>-8.5848</td>\n",
       "      <td>6.8595</td>\n",
       "      <td>10.6048</td>\n",
       "      <td>2.9890</td>\n",
       "      <td>...</td>\n",
       "      <td>4.2259</td>\n",
       "      <td>9.1723</td>\n",
       "      <td>1.2835</td>\n",
       "      <td>3.3778</td>\n",
       "      <td>19.5542</td>\n",
       "      <td>-0.2860</td>\n",
       "      <td>-5.1612</td>\n",
       "      <td>7.2882</td>\n",
       "      <td>13.9260</td>\n",
       "      <td>-9.1846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_code    var_0    var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  test_0  11.0656   7.7798  12.9536  9.4292  11.4327 -2.3805  5.8493   \n",
       "1  test_1   8.5304   1.2543  11.3047  5.1858   9.1974 -4.0117  6.0196   \n",
       "2  test_2   5.4827 -10.3581  10.1407  7.0479  10.2628  9.8052  4.8950   \n",
       "3  test_3   8.5374  -1.3222  12.0220  6.5749   8.8458  3.1744  4.9397   \n",
       "4  test_4  11.7058  -0.1327  14.1295  7.7506   9.1035 -8.5848  6.8595   \n",
       "\n",
       "     var_7   var_8  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.2675  2.1337  ...  -2.1556  11.8495  -1.4300   2.4508  13.7112   2.4669   \n",
       "1  18.6316 -4.4131  ...  10.6165   8.8349   0.9403  10.1282  15.5765   0.4773   \n",
       "2  20.2537  1.5233  ...  -0.7484  10.9935   1.9803   2.1800  12.9813   2.1281   \n",
       "3  20.5660  3.3755  ...   9.5702   9.0766   1.6580   3.5813  15.1874   3.1656   \n",
       "4  10.6048  2.9890  ...   4.2259   9.1723   1.2835   3.3778  19.5542  -0.2860   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   4.3654  10.7200  15.4722  -8.7197  \n",
       "1  -1.4852   9.8714  19.1293 -20.9760  \n",
       "2  -7.1086   7.0618  19.8956 -23.1794  \n",
       "3   3.9567   9.2295  13.0168  -4.2108  \n",
       "4  -5.1612   7.2882  13.9260  -9.1846  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fTest = pd.read_csv('Resources/test.csv')\n",
    "fTest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6ecf5be-88a0-4f57-867e-5a5053c1b541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code  target    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
       "1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n",
       "2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n",
       "3  train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428   \n",
       "4  train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405   \n",
       "\n",
       "     var_7  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.6266  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
       "1  16.5338  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
       "2  14.6155  ...   2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
       "3  14.9250  ...   4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
       "4  19.2514  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   7.8784   8.5635  12.7803  -1.0914  \n",
       "1   8.1267   8.7889  18.3560   1.9518  \n",
       "2  -6.5213   8.2675  14.7222   0.3965  \n",
       "3  -2.9275  10.2922  17.9697  -8.9996  \n",
       "4   3.9267   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrain=pd.read_csv('Resources/train.csv')\n",
    "dfTrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e9515b1-11bb-4d6b-90a0-e27e3e6884dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((160000, 200), (40000, 200), (160000,), (40000,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_columns=[c for c in dfTrain.columns if c not in ['ID_code', 'target']]\n",
    "X = dfTrain.loc[:, var_columns]\n",
    "y=dfTrain.loc[:, 'target']\n",
    "X_train, X_valid, y_train, y_valid = train_test_split (X,y, test_size=.2)\n",
    "X_train.shape, X_valid.shape, y_train.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3e0c4f7-3f3d-4ea9-8272-527a9c092780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'binary:logistic',\n",
       " 'use_label_encoder': True,\n",
       " 'base_score': None,\n",
       " 'booster': None,\n",
       " 'colsample_bylevel': None,\n",
       " 'colsample_bynode': None,\n",
       " 'colsample_bytree': None,\n",
       " 'enable_categorical': False,\n",
       " 'gamma': None,\n",
       " 'gpu_id': None,\n",
       " 'importance_type': None,\n",
       " 'interaction_constraints': None,\n",
       " 'learning_rate': None,\n",
       " 'max_delta_step': None,\n",
       " 'max_depth': None,\n",
       " 'min_child_weight': None,\n",
       " 'missing': nan,\n",
       " 'monotone_constraints': None,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'num_parallel_tree': None,\n",
       " 'predictor': None,\n",
       " 'random_state': None,\n",
       " 'reg_alpha': None,\n",
       " 'reg_lambda': None,\n",
       " 'scale_pos_weight': None,\n",
       " 'subsample': None,\n",
       " 'tree_method': None,\n",
       " 'validate_parameters': None,\n",
       " 'verbosity': None}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.XGBClassifier().get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ee5e134-51c8-4276-a68a-0755d7f9a77f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lakshmi\\anaconda3\\envs\\dev\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.60947\n",
      "[1]\tvalidation_0-auc:0.66526\n",
      "[2]\tvalidation_0-auc:0.67111\n",
      "[3]\tvalidation_0-auc:0.67777\n",
      "[4]\tvalidation_0-auc:0.68010\n",
      "[5]\tvalidation_0-auc:0.69071\n",
      "[6]\tvalidation_0-auc:0.69106\n",
      "[7]\tvalidation_0-auc:0.69239\n",
      "[8]\tvalidation_0-auc:0.69677\n",
      "[9]\tvalidation_0-auc:0.69817\n",
      "[10]\tvalidation_0-auc:0.69788\n",
      "[11]\tvalidation_0-auc:0.69959\n",
      "[12]\tvalidation_0-auc:0.70463\n",
      "[13]\tvalidation_0-auc:0.70918\n",
      "[14]\tvalidation_0-auc:0.70917\n",
      "[15]\tvalidation_0-auc:0.71228\n",
      "[16]\tvalidation_0-auc:0.71145\n",
      "[17]\tvalidation_0-auc:0.71341\n",
      "[18]\tvalidation_0-auc:0.71393\n",
      "[19]\tvalidation_0-auc:0.71436\n",
      "[20]\tvalidation_0-auc:0.71496\n",
      "[21]\tvalidation_0-auc:0.71648\n",
      "[22]\tvalidation_0-auc:0.71681\n",
      "[23]\tvalidation_0-auc:0.71986\n",
      "[24]\tvalidation_0-auc:0.72043\n",
      "[25]\tvalidation_0-auc:0.72092\n",
      "[26]\tvalidation_0-auc:0.72156\n",
      "[27]\tvalidation_0-auc:0.72181\n",
      "[28]\tvalidation_0-auc:0.72209\n",
      "[29]\tvalidation_0-auc:0.72242\n",
      "[30]\tvalidation_0-auc:0.72126\n",
      "[31]\tvalidation_0-auc:0.72287\n",
      "[32]\tvalidation_0-auc:0.72367\n",
      "[33]\tvalidation_0-auc:0.72595\n",
      "[34]\tvalidation_0-auc:0.72590\n",
      "[35]\tvalidation_0-auc:0.72602\n",
      "[36]\tvalidation_0-auc:0.72869\n",
      "[37]\tvalidation_0-auc:0.72899\n",
      "[38]\tvalidation_0-auc:0.72958\n",
      "[39]\tvalidation_0-auc:0.73020\n",
      "[40]\tvalidation_0-auc:0.73011\n",
      "[41]\tvalidation_0-auc:0.73035\n",
      "[42]\tvalidation_0-auc:0.73076\n",
      "[43]\tvalidation_0-auc:0.73113\n",
      "[44]\tvalidation_0-auc:0.73159\n",
      "[45]\tvalidation_0-auc:0.73111\n",
      "[46]\tvalidation_0-auc:0.73072\n",
      "[47]\tvalidation_0-auc:0.73168\n",
      "[48]\tvalidation_0-auc:0.73159\n",
      "[49]\tvalidation_0-auc:0.73190\n",
      "[50]\tvalidation_0-auc:0.73237\n",
      "[51]\tvalidation_0-auc:0.73300\n",
      "[52]\tvalidation_0-auc:0.73369\n",
      "[53]\tvalidation_0-auc:0.73381\n",
      "[54]\tvalidation_0-auc:0.73431\n",
      "[55]\tvalidation_0-auc:0.73466\n",
      "[56]\tvalidation_0-auc:0.73528\n",
      "[57]\tvalidation_0-auc:0.73559\n",
      "[58]\tvalidation_0-auc:0.73577\n",
      "[59]\tvalidation_0-auc:0.73593\n",
      "[60]\tvalidation_0-auc:0.73632\n",
      "[61]\tvalidation_0-auc:0.73726\n",
      "[62]\tvalidation_0-auc:0.73769\n",
      "[63]\tvalidation_0-auc:0.73790\n",
      "[64]\tvalidation_0-auc:0.73781\n",
      "[65]\tvalidation_0-auc:0.73749\n",
      "[66]\tvalidation_0-auc:0.73828\n",
      "[67]\tvalidation_0-auc:0.73889\n",
      "[68]\tvalidation_0-auc:0.73951\n",
      "[69]\tvalidation_0-auc:0.73984\n",
      "[70]\tvalidation_0-auc:0.74051\n",
      "[71]\tvalidation_0-auc:0.74087\n",
      "[72]\tvalidation_0-auc:0.74098\n",
      "[73]\tvalidation_0-auc:0.74100\n",
      "[74]\tvalidation_0-auc:0.74174\n",
      "[75]\tvalidation_0-auc:0.74247\n",
      "[76]\tvalidation_0-auc:0.74244\n",
      "[77]\tvalidation_0-auc:0.74266\n",
      "[78]\tvalidation_0-auc:0.74256\n",
      "[79]\tvalidation_0-auc:0.74277\n",
      "[80]\tvalidation_0-auc:0.74277\n",
      "[81]\tvalidation_0-auc:0.74261\n",
      "[82]\tvalidation_0-auc:0.74308\n",
      "[83]\tvalidation_0-auc:0.74350\n",
      "[84]\tvalidation_0-auc:0.74309\n",
      "[85]\tvalidation_0-auc:0.74363\n",
      "[86]\tvalidation_0-auc:0.74382\n",
      "[87]\tvalidation_0-auc:0.74357\n",
      "[88]\tvalidation_0-auc:0.74341\n",
      "[89]\tvalidation_0-auc:0.74342\n",
      "[90]\tvalidation_0-auc:0.74396\n",
      "[91]\tvalidation_0-auc:0.74362\n",
      "[92]\tvalidation_0-auc:0.74347\n",
      "[93]\tvalidation_0-auc:0.74353\n",
      "[94]\tvalidation_0-auc:0.74359\n",
      "[95]\tvalidation_0-auc:0.74338\n",
      "[96]\tvalidation_0-auc:0.74408\n",
      "[97]\tvalidation_0-auc:0.74471\n",
      "[98]\tvalidation_0-auc:0.74482\n",
      "[99]\tvalidation_0-auc:0.74554\n",
      "[100]\tvalidation_0-auc:0.74595\n",
      "[101]\tvalidation_0-auc:0.74572\n",
      "[102]\tvalidation_0-auc:0.74569\n",
      "[103]\tvalidation_0-auc:0.74601\n",
      "[104]\tvalidation_0-auc:0.74587\n",
      "[105]\tvalidation_0-auc:0.74630\n",
      "[106]\tvalidation_0-auc:0.74674\n",
      "[107]\tvalidation_0-auc:0.74695\n",
      "[108]\tvalidation_0-auc:0.74670\n",
      "[109]\tvalidation_0-auc:0.74704\n",
      "[110]\tvalidation_0-auc:0.74709\n",
      "[111]\tvalidation_0-auc:0.74667\n",
      "[112]\tvalidation_0-auc:0.74714\n",
      "[113]\tvalidation_0-auc:0.74732\n",
      "[114]\tvalidation_0-auc:0.74721\n",
      "[115]\tvalidation_0-auc:0.74743\n",
      "[116]\tvalidation_0-auc:0.74782\n",
      "[117]\tvalidation_0-auc:0.74832\n",
      "[118]\tvalidation_0-auc:0.74910\n",
      "[119]\tvalidation_0-auc:0.74946\n",
      "[120]\tvalidation_0-auc:0.74951\n",
      "[121]\tvalidation_0-auc:0.75001\n",
      "[122]\tvalidation_0-auc:0.75017\n",
      "[123]\tvalidation_0-auc:0.75083\n",
      "[124]\tvalidation_0-auc:0.75056\n",
      "[125]\tvalidation_0-auc:0.75071\n",
      "[126]\tvalidation_0-auc:0.75097\n",
      "[127]\tvalidation_0-auc:0.75130\n",
      "[128]\tvalidation_0-auc:0.75197\n",
      "[129]\tvalidation_0-auc:0.75218\n",
      "[130]\tvalidation_0-auc:0.75198\n",
      "[131]\tvalidation_0-auc:0.75205\n",
      "[132]\tvalidation_0-auc:0.75235\n",
      "[133]\tvalidation_0-auc:0.75250\n",
      "[134]\tvalidation_0-auc:0.75319\n",
      "[135]\tvalidation_0-auc:0.75331\n",
      "[136]\tvalidation_0-auc:0.75320\n",
      "[137]\tvalidation_0-auc:0.75385\n",
      "[138]\tvalidation_0-auc:0.75423\n",
      "[139]\tvalidation_0-auc:0.75453\n",
      "[140]\tvalidation_0-auc:0.75489\n",
      "[141]\tvalidation_0-auc:0.75522\n",
      "[142]\tvalidation_0-auc:0.75529\n",
      "[143]\tvalidation_0-auc:0.75617\n",
      "[144]\tvalidation_0-auc:0.75656\n",
      "[145]\tvalidation_0-auc:0.75637\n",
      "[146]\tvalidation_0-auc:0.75643\n",
      "[147]\tvalidation_0-auc:0.75654\n",
      "[148]\tvalidation_0-auc:0.75688\n",
      "[149]\tvalidation_0-auc:0.75758\n",
      "[150]\tvalidation_0-auc:0.75809\n",
      "[151]\tvalidation_0-auc:0.75834\n",
      "[152]\tvalidation_0-auc:0.75843\n",
      "[153]\tvalidation_0-auc:0.75835\n",
      "[154]\tvalidation_0-auc:0.75894\n",
      "[155]\tvalidation_0-auc:0.75924\n",
      "[156]\tvalidation_0-auc:0.75975\n",
      "[157]\tvalidation_0-auc:0.76020\n",
      "[158]\tvalidation_0-auc:0.76049\n",
      "[159]\tvalidation_0-auc:0.76074\n",
      "[160]\tvalidation_0-auc:0.76071\n",
      "[161]\tvalidation_0-auc:0.76081\n",
      "[162]\tvalidation_0-auc:0.76073\n",
      "[163]\tvalidation_0-auc:0.76101\n",
      "[164]\tvalidation_0-auc:0.76149\n",
      "[165]\tvalidation_0-auc:0.76167\n",
      "[166]\tvalidation_0-auc:0.76160\n",
      "[167]\tvalidation_0-auc:0.76173\n",
      "[168]\tvalidation_0-auc:0.76211\n",
      "[169]\tvalidation_0-auc:0.76237\n",
      "[170]\tvalidation_0-auc:0.76248\n",
      "[171]\tvalidation_0-auc:0.76258\n",
      "[172]\tvalidation_0-auc:0.76295\n",
      "[173]\tvalidation_0-auc:0.76326\n",
      "[174]\tvalidation_0-auc:0.76359\n",
      "[175]\tvalidation_0-auc:0.76409\n",
      "[176]\tvalidation_0-auc:0.76434\n",
      "[177]\tvalidation_0-auc:0.76433\n",
      "[178]\tvalidation_0-auc:0.76490\n",
      "[179]\tvalidation_0-auc:0.76526\n",
      "[180]\tvalidation_0-auc:0.76564\n",
      "[181]\tvalidation_0-auc:0.76579\n",
      "[182]\tvalidation_0-auc:0.76629\n",
      "[183]\tvalidation_0-auc:0.76654\n",
      "[184]\tvalidation_0-auc:0.76685\n",
      "[185]\tvalidation_0-auc:0.76759\n",
      "[186]\tvalidation_0-auc:0.76794\n",
      "[187]\tvalidation_0-auc:0.76828\n",
      "[188]\tvalidation_0-auc:0.76829\n",
      "[189]\tvalidation_0-auc:0.76814\n",
      "[190]\tvalidation_0-auc:0.76820\n",
      "[191]\tvalidation_0-auc:0.76859\n",
      "[192]\tvalidation_0-auc:0.76879\n",
      "[193]\tvalidation_0-auc:0.76926\n",
      "[194]\tvalidation_0-auc:0.76934\n",
      "[195]\tvalidation_0-auc:0.76992\n",
      "[196]\tvalidation_0-auc:0.77024\n",
      "[197]\tvalidation_0-auc:0.77026\n",
      "[198]\tvalidation_0-auc:0.77031\n",
      "[199]\tvalidation_0-auc:0.77077\n",
      "[200]\tvalidation_0-auc:0.77123\n",
      "[201]\tvalidation_0-auc:0.77163\n",
      "[202]\tvalidation_0-auc:0.77165\n",
      "[203]\tvalidation_0-auc:0.77163\n",
      "[204]\tvalidation_0-auc:0.77170\n",
      "[205]\tvalidation_0-auc:0.77238\n",
      "[206]\tvalidation_0-auc:0.77251\n",
      "[207]\tvalidation_0-auc:0.77276\n",
      "[208]\tvalidation_0-auc:0.77302\n",
      "[209]\tvalidation_0-auc:0.77311\n",
      "[210]\tvalidation_0-auc:0.77334\n",
      "[211]\tvalidation_0-auc:0.77332\n",
      "[212]\tvalidation_0-auc:0.77393\n",
      "[213]\tvalidation_0-auc:0.77432\n",
      "[214]\tvalidation_0-auc:0.77454\n",
      "[215]\tvalidation_0-auc:0.77494\n",
      "[216]\tvalidation_0-auc:0.77507\n",
      "[217]\tvalidation_0-auc:0.77535\n",
      "[218]\tvalidation_0-auc:0.77580\n",
      "[219]\tvalidation_0-auc:0.77631\n",
      "[220]\tvalidation_0-auc:0.77648\n",
      "[221]\tvalidation_0-auc:0.77684\n",
      "[222]\tvalidation_0-auc:0.77721\n",
      "[223]\tvalidation_0-auc:0.77746\n",
      "[224]\tvalidation_0-auc:0.77747\n",
      "[225]\tvalidation_0-auc:0.77790\n",
      "[226]\tvalidation_0-auc:0.77829\n",
      "[227]\tvalidation_0-auc:0.77857\n",
      "[228]\tvalidation_0-auc:0.77902\n",
      "[229]\tvalidation_0-auc:0.77926\n",
      "[230]\tvalidation_0-auc:0.77957\n",
      "[231]\tvalidation_0-auc:0.77951\n",
      "[232]\tvalidation_0-auc:0.77975\n",
      "[233]\tvalidation_0-auc:0.77985\n",
      "[234]\tvalidation_0-auc:0.77984\n",
      "[235]\tvalidation_0-auc:0.78039\n",
      "[236]\tvalidation_0-auc:0.78053\n",
      "[237]\tvalidation_0-auc:0.78061\n",
      "[238]\tvalidation_0-auc:0.78051\n",
      "[239]\tvalidation_0-auc:0.78057\n",
      "[240]\tvalidation_0-auc:0.78094\n",
      "[241]\tvalidation_0-auc:0.78144\n",
      "[242]\tvalidation_0-auc:0.78140\n",
      "[243]\tvalidation_0-auc:0.78137\n",
      "[244]\tvalidation_0-auc:0.78146\n",
      "[245]\tvalidation_0-auc:0.78156\n",
      "[246]\tvalidation_0-auc:0.78175\n",
      "[247]\tvalidation_0-auc:0.78196\n",
      "[248]\tvalidation_0-auc:0.78196\n",
      "[249]\tvalidation_0-auc:0.78223\n",
      "[250]\tvalidation_0-auc:0.78228\n",
      "[251]\tvalidation_0-auc:0.78258\n",
      "[252]\tvalidation_0-auc:0.78293\n",
      "[253]\tvalidation_0-auc:0.78326\n",
      "[254]\tvalidation_0-auc:0.78335\n",
      "[255]\tvalidation_0-auc:0.78363\n",
      "[256]\tvalidation_0-auc:0.78378\n",
      "[257]\tvalidation_0-auc:0.78398\n",
      "[258]\tvalidation_0-auc:0.78406\n",
      "[259]\tvalidation_0-auc:0.78431\n",
      "[260]\tvalidation_0-auc:0.78446\n",
      "[261]\tvalidation_0-auc:0.78493\n",
      "[262]\tvalidation_0-auc:0.78541\n",
      "[263]\tvalidation_0-auc:0.78578\n",
      "[264]\tvalidation_0-auc:0.78630\n",
      "[265]\tvalidation_0-auc:0.78663\n",
      "[266]\tvalidation_0-auc:0.78685\n",
      "[267]\tvalidation_0-auc:0.78722\n",
      "[268]\tvalidation_0-auc:0.78747\n",
      "[269]\tvalidation_0-auc:0.78774\n",
      "[270]\tvalidation_0-auc:0.78790\n",
      "[271]\tvalidation_0-auc:0.78813\n",
      "[272]\tvalidation_0-auc:0.78862\n",
      "[273]\tvalidation_0-auc:0.78860\n",
      "[274]\tvalidation_0-auc:0.78866\n",
      "[275]\tvalidation_0-auc:0.78904\n",
      "[276]\tvalidation_0-auc:0.78926\n",
      "[277]\tvalidation_0-auc:0.78947\n",
      "[278]\tvalidation_0-auc:0.78988\n",
      "[279]\tvalidation_0-auc:0.79009\n",
      "[280]\tvalidation_0-auc:0.79014\n",
      "[281]\tvalidation_0-auc:0.79028\n",
      "[282]\tvalidation_0-auc:0.79051\n",
      "[283]\tvalidation_0-auc:0.79078\n",
      "[284]\tvalidation_0-auc:0.79101\n",
      "[285]\tvalidation_0-auc:0.79105\n",
      "[286]\tvalidation_0-auc:0.79139\n",
      "[287]\tvalidation_0-auc:0.79136\n",
      "[288]\tvalidation_0-auc:0.79158\n",
      "[289]\tvalidation_0-auc:0.79204\n",
      "[290]\tvalidation_0-auc:0.79210\n",
      "[291]\tvalidation_0-auc:0.79221\n",
      "[292]\tvalidation_0-auc:0.79248\n",
      "[293]\tvalidation_0-auc:0.79253\n",
      "[294]\tvalidation_0-auc:0.79283\n",
      "[295]\tvalidation_0-auc:0.79288\n",
      "[296]\tvalidation_0-auc:0.79300\n",
      "[297]\tvalidation_0-auc:0.79332\n",
      "[298]\tvalidation_0-auc:0.79357\n",
      "[299]\tvalidation_0-auc:0.79362\n",
      "[300]\tvalidation_0-auc:0.79402\n",
      "[301]\tvalidation_0-auc:0.79405\n",
      "[302]\tvalidation_0-auc:0.79448\n",
      "[303]\tvalidation_0-auc:0.79466\n",
      "[304]\tvalidation_0-auc:0.79482\n",
      "[305]\tvalidation_0-auc:0.79503\n",
      "[306]\tvalidation_0-auc:0.79514\n",
      "[307]\tvalidation_0-auc:0.79528\n",
      "[308]\tvalidation_0-auc:0.79559\n",
      "[309]\tvalidation_0-auc:0.79580\n",
      "[310]\tvalidation_0-auc:0.79632\n",
      "[311]\tvalidation_0-auc:0.79637\n",
      "[312]\tvalidation_0-auc:0.79663\n",
      "[313]\tvalidation_0-auc:0.79682\n",
      "[314]\tvalidation_0-auc:0.79704\n",
      "[315]\tvalidation_0-auc:0.79699\n",
      "[316]\tvalidation_0-auc:0.79722\n",
      "[317]\tvalidation_0-auc:0.79749\n",
      "[318]\tvalidation_0-auc:0.79753\n",
      "[319]\tvalidation_0-auc:0.79796\n",
      "[320]\tvalidation_0-auc:0.79788\n",
      "[321]\tvalidation_0-auc:0.79815\n",
      "[322]\tvalidation_0-auc:0.79828\n",
      "[323]\tvalidation_0-auc:0.79844\n",
      "[324]\tvalidation_0-auc:0.79877\n",
      "[325]\tvalidation_0-auc:0.79904\n",
      "[326]\tvalidation_0-auc:0.79941\n",
      "[327]\tvalidation_0-auc:0.79971\n",
      "[328]\tvalidation_0-auc:0.79997\n",
      "[329]\tvalidation_0-auc:0.80024\n",
      "[330]\tvalidation_0-auc:0.80060\n",
      "[331]\tvalidation_0-auc:0.80082\n",
      "[332]\tvalidation_0-auc:0.80101\n",
      "[333]\tvalidation_0-auc:0.80114\n",
      "[334]\tvalidation_0-auc:0.80139\n",
      "[335]\tvalidation_0-auc:0.80159\n",
      "[336]\tvalidation_0-auc:0.80173\n",
      "[337]\tvalidation_0-auc:0.80191\n",
      "[338]\tvalidation_0-auc:0.80212\n",
      "[339]\tvalidation_0-auc:0.80231\n",
      "[340]\tvalidation_0-auc:0.80255\n",
      "[341]\tvalidation_0-auc:0.80279\n",
      "[342]\tvalidation_0-auc:0.80297\n",
      "[343]\tvalidation_0-auc:0.80313\n",
      "[344]\tvalidation_0-auc:0.80318\n",
      "[345]\tvalidation_0-auc:0.80322\n",
      "[346]\tvalidation_0-auc:0.80326\n",
      "[347]\tvalidation_0-auc:0.80343\n",
      "[348]\tvalidation_0-auc:0.80356\n",
      "[349]\tvalidation_0-auc:0.80380\n",
      "[350]\tvalidation_0-auc:0.80401\n",
      "[351]\tvalidation_0-auc:0.80411\n",
      "[352]\tvalidation_0-auc:0.80408\n",
      "[353]\tvalidation_0-auc:0.80434\n",
      "[354]\tvalidation_0-auc:0.80454\n",
      "[355]\tvalidation_0-auc:0.80468\n",
      "[356]\tvalidation_0-auc:0.80492\n",
      "[357]\tvalidation_0-auc:0.80510\n",
      "[358]\tvalidation_0-auc:0.80535\n",
      "[359]\tvalidation_0-auc:0.80568\n",
      "[360]\tvalidation_0-auc:0.80603\n",
      "[361]\tvalidation_0-auc:0.80596\n",
      "[362]\tvalidation_0-auc:0.80605\n",
      "[363]\tvalidation_0-auc:0.80615\n",
      "[364]\tvalidation_0-auc:0.80642\n",
      "[365]\tvalidation_0-auc:0.80636\n",
      "[366]\tvalidation_0-auc:0.80663\n",
      "[367]\tvalidation_0-auc:0.80670\n",
      "[368]\tvalidation_0-auc:0.80697\n",
      "[369]\tvalidation_0-auc:0.80709\n",
      "[370]\tvalidation_0-auc:0.80721\n",
      "[371]\tvalidation_0-auc:0.80739\n",
      "[372]\tvalidation_0-auc:0.80752\n",
      "[373]\tvalidation_0-auc:0.80776\n",
      "[374]\tvalidation_0-auc:0.80794\n",
      "[375]\tvalidation_0-auc:0.80814\n",
      "[376]\tvalidation_0-auc:0.80831\n",
      "[377]\tvalidation_0-auc:0.80856\n",
      "[378]\tvalidation_0-auc:0.80851\n",
      "[379]\tvalidation_0-auc:0.80865\n",
      "[380]\tvalidation_0-auc:0.80876\n",
      "[381]\tvalidation_0-auc:0.80889\n",
      "[382]\tvalidation_0-auc:0.80895\n",
      "[383]\tvalidation_0-auc:0.80922\n",
      "[384]\tvalidation_0-auc:0.80921\n",
      "[385]\tvalidation_0-auc:0.80937\n",
      "[386]\tvalidation_0-auc:0.80957\n",
      "[387]\tvalidation_0-auc:0.80969\n",
      "[388]\tvalidation_0-auc:0.80981\n",
      "[389]\tvalidation_0-auc:0.81013\n",
      "[390]\tvalidation_0-auc:0.81025\n",
      "[391]\tvalidation_0-auc:0.81042\n",
      "[392]\tvalidation_0-auc:0.81071\n",
      "[393]\tvalidation_0-auc:0.81087\n",
      "[394]\tvalidation_0-auc:0.81098\n",
      "[395]\tvalidation_0-auc:0.81106\n",
      "[396]\tvalidation_0-auc:0.81118\n",
      "[397]\tvalidation_0-auc:0.81132\n",
      "[398]\tvalidation_0-auc:0.81141\n",
      "[399]\tvalidation_0-auc:0.81163\n",
      "[400]\tvalidation_0-auc:0.81189\n",
      "[401]\tvalidation_0-auc:0.81213\n",
      "[402]\tvalidation_0-auc:0.81218\n",
      "[403]\tvalidation_0-auc:0.81228\n",
      "[404]\tvalidation_0-auc:0.81247\n",
      "[405]\tvalidation_0-auc:0.81266\n",
      "[406]\tvalidation_0-auc:0.81282\n",
      "[407]\tvalidation_0-auc:0.81294\n",
      "[408]\tvalidation_0-auc:0.81318\n",
      "[409]\tvalidation_0-auc:0.81336\n",
      "[410]\tvalidation_0-auc:0.81351\n",
      "[411]\tvalidation_0-auc:0.81365\n",
      "[412]\tvalidation_0-auc:0.81369\n",
      "[413]\tvalidation_0-auc:0.81383\n",
      "[414]\tvalidation_0-auc:0.81393\n",
      "[415]\tvalidation_0-auc:0.81392\n",
      "[416]\tvalidation_0-auc:0.81406\n",
      "[417]\tvalidation_0-auc:0.81418\n",
      "[418]\tvalidation_0-auc:0.81428\n",
      "[419]\tvalidation_0-auc:0.81453\n",
      "[420]\tvalidation_0-auc:0.81455\n",
      "[421]\tvalidation_0-auc:0.81460\n",
      "[422]\tvalidation_0-auc:0.81475\n",
      "[423]\tvalidation_0-auc:0.81475\n",
      "[424]\tvalidation_0-auc:0.81486\n",
      "[425]\tvalidation_0-auc:0.81503\n",
      "[426]\tvalidation_0-auc:0.81515\n",
      "[427]\tvalidation_0-auc:0.81532\n",
      "[428]\tvalidation_0-auc:0.81542\n",
      "[429]\tvalidation_0-auc:0.81546\n",
      "[430]\tvalidation_0-auc:0.81551\n",
      "[431]\tvalidation_0-auc:0.81573\n",
      "[432]\tvalidation_0-auc:0.81597\n",
      "[433]\tvalidation_0-auc:0.81613\n",
      "[434]\tvalidation_0-auc:0.81637\n",
      "[435]\tvalidation_0-auc:0.81661\n",
      "[436]\tvalidation_0-auc:0.81657\n",
      "[437]\tvalidation_0-auc:0.81678\n",
      "[438]\tvalidation_0-auc:0.81701\n",
      "[439]\tvalidation_0-auc:0.81716\n",
      "[440]\tvalidation_0-auc:0.81732\n",
      "[441]\tvalidation_0-auc:0.81753\n",
      "[442]\tvalidation_0-auc:0.81766\n",
      "[443]\tvalidation_0-auc:0.81780\n",
      "[444]\tvalidation_0-auc:0.81796\n",
      "[445]\tvalidation_0-auc:0.81822\n",
      "[446]\tvalidation_0-auc:0.81838\n",
      "[447]\tvalidation_0-auc:0.81848\n",
      "[448]\tvalidation_0-auc:0.81870\n",
      "[449]\tvalidation_0-auc:0.81882\n",
      "[450]\tvalidation_0-auc:0.81881\n",
      "[451]\tvalidation_0-auc:0.81896\n",
      "[452]\tvalidation_0-auc:0.81924\n",
      "[453]\tvalidation_0-auc:0.81942\n",
      "[454]\tvalidation_0-auc:0.81966\n",
      "[455]\tvalidation_0-auc:0.81984\n",
      "[456]\tvalidation_0-auc:0.81998\n",
      "[457]\tvalidation_0-auc:0.82008\n",
      "[458]\tvalidation_0-auc:0.82017\n",
      "[459]\tvalidation_0-auc:0.82040\n",
      "[460]\tvalidation_0-auc:0.82059\n",
      "[461]\tvalidation_0-auc:0.82082\n",
      "[462]\tvalidation_0-auc:0.82099\n",
      "[463]\tvalidation_0-auc:0.82120\n",
      "[464]\tvalidation_0-auc:0.82137\n",
      "[465]\tvalidation_0-auc:0.82149\n",
      "[466]\tvalidation_0-auc:0.82169\n",
      "[467]\tvalidation_0-auc:0.82183\n",
      "[468]\tvalidation_0-auc:0.82197\n",
      "[469]\tvalidation_0-auc:0.82195\n",
      "[470]\tvalidation_0-auc:0.82205\n",
      "[471]\tvalidation_0-auc:0.82225\n",
      "[472]\tvalidation_0-auc:0.82238\n",
      "[473]\tvalidation_0-auc:0.82247\n",
      "[474]\tvalidation_0-auc:0.82245\n",
      "[475]\tvalidation_0-auc:0.82268\n",
      "[476]\tvalidation_0-auc:0.82285\n",
      "[477]\tvalidation_0-auc:0.82294\n",
      "[478]\tvalidation_0-auc:0.82311\n",
      "[479]\tvalidation_0-auc:0.82315\n",
      "[480]\tvalidation_0-auc:0.82325\n",
      "[481]\tvalidation_0-auc:0.82334\n",
      "[482]\tvalidation_0-auc:0.82349\n",
      "[483]\tvalidation_0-auc:0.82356\n",
      "[484]\tvalidation_0-auc:0.82366\n",
      "[485]\tvalidation_0-auc:0.82370\n",
      "[486]\tvalidation_0-auc:0.82377\n",
      "[487]\tvalidation_0-auc:0.82393\n",
      "[488]\tvalidation_0-auc:0.82412\n",
      "[489]\tvalidation_0-auc:0.82432\n",
      "[490]\tvalidation_0-auc:0.82442\n",
      "[491]\tvalidation_0-auc:0.82455\n",
      "[492]\tvalidation_0-auc:0.82461\n",
      "[493]\tvalidation_0-auc:0.82477\n",
      "[494]\tvalidation_0-auc:0.82475\n",
      "[495]\tvalidation_0-auc:0.82494\n",
      "[496]\tvalidation_0-auc:0.82500\n",
      "[497]\tvalidation_0-auc:0.82514\n",
      "[498]\tvalidation_0-auc:0.82521\n",
      "[499]\tvalidation_0-auc:0.82535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.5,\n",
       "              enable_categorical=False, eval_metric='auc', gamma=0, gpu_id=-1,\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.01, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=500, n_jobs=4, num_parallel_tree=1, predictor='auto',\n",
       "              random_state=1, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              subsample=0.5, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgboost = xgb.XGBClassifier(learning_rate=.01,\n",
    "                                     max_depth=5,\n",
    "                                     n_estimators=500,\n",
    "                                     subsample=.5,\n",
    "                                     colsample_bytree=.5,\n",
    "                                     eval_metric='auc',\n",
    "                                     verbosity=1,\n",
    "                                    random_state=1)\n",
    "\n",
    "eval_set =[(X_valid, y_valid)]\n",
    "\n",
    "model_xgboost.fit(X_train,\n",
    "                 y_train,\n",
    "                 early_stopping_rounds=10,\n",
    "                 eval_set=eval_set,\n",
    "                 verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e004e4-841e-44ff-923f-ade4a55c313c",
   "metadata": {},
   "source": [
    "# Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3db96e3e-5b9b-4c9a-9f22-4bf3a94d9916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Train: 0.8732\n",
      "AUC Valid 0.8254\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = model_xgboost.predict_proba(X_train)[:,1]\n",
    "y_valid_pred = model_xgboost.predict_proba(X_valid)[:,1]\n",
    "\n",
    "print(\"AUC Train: {:.4f}\\nAUC Valid {:.4f}\".format(roc_auc_score(y_train, y_train_pred), roc_auc_score(y_valid,y_valid_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667e9393-c8a4-414e-99ec-b2ddd777c096",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c89bafe9-c054-4655-8507-2d2133f7ceb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': [0.05, 0.1, 0.15],\n",
       " 'njobs': [2, 4, 6],\n",
       " 'baseScore': [0.3, 0.5, 0.7]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = [0.05, .1, .15]\n",
    "n_jobs = [2, 4, 6]\n",
    "base_score = [0.3,0.5,0.7]\n",
    "\n",
    "params_dict = {\"learning_rate\": learning_rate,\n",
    "              \"njobs\":n_jobs,\n",
    "              \"baseScore\":base_score}\n",
    "\n",
    "num_combinations = 1\n",
    "for v in params_dict.values(): num_combinations *=len(v)\n",
    "    \n",
    "print (num_combinations)\n",
    "params_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3237a4c3-5b0c-4cd9-8293-b7e86bda2322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 27 candidates, totalling 54 fits\n",
      "[12:17:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/2] END .....baseScore=0.3, learning_rate=0.05, njobs=2; total time= 1.4min\n",
      "[12:18:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/2] END .....baseScore=0.3, learning_rate=0.05, njobs=2; total time= 1.0min\n",
      "[12:19:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/2] END .....baseScore=0.3, learning_rate=0.05, njobs=4; total time= 1.0min\n",
      "[12:20:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/2] END .....baseScore=0.3, learning_rate=0.05, njobs=4; total time= 1.0min\n",
      "[12:21:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/2] END .....baseScore=0.3, learning_rate=0.05, njobs=6; total time= 1.1min\n",
      "[12:22:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/2] END .....baseScore=0.3, learning_rate=0.05, njobs=6; total time= 1.1min\n",
      "[12:23:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/2] END ......baseScore=0.3, learning_rate=0.1, njobs=2; total time= 1.1min\n",
      "[12:24:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/2] END ......baseScore=0.3, learning_rate=0.1, njobs=2; total time= 1.4min\n",
      "[12:26:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/2] END ......baseScore=0.3, learning_rate=0.1, njobs=4; total time= 1.4min\n",
      "[12:27:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/2] END ......baseScore=0.3, learning_rate=0.1, njobs=4; total time= 1.5min\n",
      "[12:29:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/2] END ......baseScore=0.3, learning_rate=0.1, njobs=6; total time= 1.4min\n",
      "[12:30:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/2] END ......baseScore=0.3, learning_rate=0.1, njobs=6; total time= 1.4min\n",
      "[12:32:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/2] END .....baseScore=0.3, learning_rate=0.15, njobs=2; total time= 1.4min\n",
      "[12:33:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/2] END .....baseScore=0.3, learning_rate=0.15, njobs=2; total time= 1.2min\n",
      "[12:34:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/2] END .....baseScore=0.3, learning_rate=0.15, njobs=4; total time= 1.3min\n",
      "[12:36:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/2] END .....baseScore=0.3, learning_rate=0.15, njobs=4; total time= 1.3min\n",
      "[12:37:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/2] END .....baseScore=0.3, learning_rate=0.15, njobs=6; total time= 1.3min\n",
      "[12:38:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/2] END .....baseScore=0.3, learning_rate=0.15, njobs=6; total time= 1.4min\n",
      "[12:40:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/2] END .....baseScore=0.5, learning_rate=0.05, njobs=2; total time= 1.3min\n",
      "[12:41:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/2] END .....baseScore=0.5, learning_rate=0.05, njobs=2; total time= 1.3min\n",
      "[12:42:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/2] END .....baseScore=0.5, learning_rate=0.05, njobs=4; total time= 1.4min\n",
      "[12:44:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/2] END .....baseScore=0.5, learning_rate=0.05, njobs=4; total time= 1.3min\n",
      "[12:45:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/2] END .....baseScore=0.5, learning_rate=0.05, njobs=6; total time= 1.3min\n",
      "[12:46:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/2] END .....baseScore=0.5, learning_rate=0.05, njobs=6; total time= 1.3min\n",
      "[12:48:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/2] END ......baseScore=0.5, learning_rate=0.1, njobs=2; total time= 1.5min\n",
      "[12:49:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/2] END ......baseScore=0.5, learning_rate=0.1, njobs=2; total time= 1.3min\n",
      "[12:51:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/2] END ......baseScore=0.5, learning_rate=0.1, njobs=4; total time= 1.3min\n",
      "[12:52:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/2] END ......baseScore=0.5, learning_rate=0.1, njobs=4; total time= 1.3min\n",
      "[12:53:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/2] END ......baseScore=0.5, learning_rate=0.1, njobs=6; total time= 1.6min\n",
      "[12:55:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/2] END ......baseScore=0.5, learning_rate=0.1, njobs=6; total time= 1.1min\n",
      "[12:56:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/2] END .....baseScore=0.5, learning_rate=0.15, njobs=2; total time= 1.0min\n",
      "[12:57:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/2] END .....baseScore=0.5, learning_rate=0.15, njobs=2; total time=  59.3s\n",
      "[12:58:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/2] END .....baseScore=0.5, learning_rate=0.15, njobs=4; total time= 1.0min\n",
      "[12:59:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/2] END .....baseScore=0.5, learning_rate=0.15, njobs=4; total time= 1.1min\n",
      "[13:00:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/2] END .....baseScore=0.5, learning_rate=0.15, njobs=6; total time=  58.6s\n",
      "[13:01:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/2] END .....baseScore=0.5, learning_rate=0.15, njobs=6; total time=  58.5s\n",
      "[13:02:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/2] END .....baseScore=0.7, learning_rate=0.05, njobs=2; total time=  57.0s\n",
      "[13:03:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/2] END .....baseScore=0.7, learning_rate=0.05, njobs=2; total time=  55.9s\n",
      "[13:04:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/2] END .....baseScore=0.7, learning_rate=0.05, njobs=4; total time=  56.0s\n",
      "[13:05:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/2] END .....baseScore=0.7, learning_rate=0.05, njobs=4; total time=  56.1s\n",
      "[13:06:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/2] END .....baseScore=0.7, learning_rate=0.05, njobs=6; total time=  54.9s\n",
      "[13:07:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/2] END .....baseScore=0.7, learning_rate=0.05, njobs=6; total time=  55.0s\n",
      "[13:08:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/2] END ......baseScore=0.7, learning_rate=0.1, njobs=2; total time=  57.2s\n",
      "[13:09:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/2] END ......baseScore=0.7, learning_rate=0.1, njobs=2; total time=  56.0s\n",
      "[13:10:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/2] END ......baseScore=0.7, learning_rate=0.1, njobs=4; total time=  58.1s\n",
      "[13:11:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/2] END ......baseScore=0.7, learning_rate=0.1, njobs=4; total time=  55.8s\n",
      "[13:12:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/2] END ......baseScore=0.7, learning_rate=0.1, njobs=6; total time=  56.0s\n",
      "[13:12:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/2] END ......baseScore=0.7, learning_rate=0.1, njobs=6; total time=  56.6s\n",
      "[13:13:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/2] END .....baseScore=0.7, learning_rate=0.15, njobs=2; total time=  56.7s\n",
      "[13:14:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/2] END .....baseScore=0.7, learning_rate=0.15, njobs=2; total time=17.3min\n",
      "[13:32:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/2] END .....baseScore=0.7, learning_rate=0.15, njobs=4; total time=  48.9s\n",
      "[13:33:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/2] END .....baseScore=0.7, learning_rate=0.15, njobs=4; total time=  49.3s\n",
      "[13:33:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/2] END .....baseScore=0.7, learning_rate=0.15, njobs=6; total time=  48.3s\n",
      "[13:34:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/2] END .....baseScore=0.7, learning_rate=0.15, njobs=6; total time=  47.3s\n",
      "[13:35:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"baseScore\", \"njobs\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=0.25,\n",
       "                                     enable_categorical=False,\n",
       "                                     eval_metric='auc', gamma=None, gpu_id=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone...\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, reg_alpha=None,\n",
       "                                     reg_lambda=None, scale_pos_weight=None,\n",
       "                                     subsample=0.5, tree_method=None,\n",
       "                                     use_label_encoder=False,\n",
       "                                     validate_parameters=None, verbosity=None),\n",
       "             param_grid={'baseScore': [0.3, 0.5, 0.7],\n",
       "                         'learning_rate': [0.05, 0.1, 0.15],\n",
       "                         'njobs': [2, 4, 6]},\n",
       "             return_train_score=True,\n",
       "             scoring=<function my_roc_auc_score at 0x000002882B15FF78>,\n",
       "             verbose=4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def my_roc_auc_score(model, X, y): return roc_auc_score(y, model.predict_proba(X)[:,1])\n",
    "\n",
    "model_xgboost_hp = GridSearchCV(estimator=xgb.XGBClassifier(subsample=0.5,\n",
    "                                                               colsample_bytree=0.25,\n",
    "                                                               eval_metric='auc',\n",
    "                                                               use_label_encoder=False),\n",
    "                               param_grid=params_dict,\n",
    "                               cv=2,\n",
    "                               scoring=my_roc_auc_score,\n",
    "                               return_train_score=True,\n",
    "                               verbose=4)\n",
    "model_xgboost_hp.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eeb889b3-fff6-4ec2-b9c8-8c3c5bd02abe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_njobs</th>\n",
       "      <th>param_baseScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>0.856159</td>\n",
       "      <td>0.956585</td>\n",
       "      <td>0.15</td>\n",
       "      <td>6</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>0.856159</td>\n",
       "      <td>0.956585</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0.856159</td>\n",
       "      <td>0.956585</td>\n",
       "      <td>0.15</td>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0.856159</td>\n",
       "      <td>0.956585</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0.856159</td>\n",
       "      <td>0.956585</td>\n",
       "      <td>0.15</td>\n",
       "      <td>4</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0.856159</td>\n",
       "      <td>0.956585</td>\n",
       "      <td>0.15</td>\n",
       "      <td>6</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0.856159</td>\n",
       "      <td>0.956585</td>\n",
       "      <td>0.15</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0.856159</td>\n",
       "      <td>0.956585</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>0.856159</td>\n",
       "      <td>0.956585</td>\n",
       "      <td>0.15</td>\n",
       "      <td>4</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10</td>\n",
       "      <td>0.854083</td>\n",
       "      <td>0.940772</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10</td>\n",
       "      <td>0.854083</td>\n",
       "      <td>0.940772</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10</td>\n",
       "      <td>0.854083</td>\n",
       "      <td>0.940772</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10</td>\n",
       "      <td>0.854083</td>\n",
       "      <td>0.940772</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10</td>\n",
       "      <td>0.854083</td>\n",
       "      <td>0.940772</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>0.854083</td>\n",
       "      <td>0.940772</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0.854083</td>\n",
       "      <td>0.940772</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0.854083</td>\n",
       "      <td>0.940772</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>0.854083</td>\n",
       "      <td>0.940772</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>19</td>\n",
       "      <td>0.835087</td>\n",
       "      <td>0.907782</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>19</td>\n",
       "      <td>0.835087</td>\n",
       "      <td>0.907782</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19</td>\n",
       "      <td>0.835087</td>\n",
       "      <td>0.907782</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.835087</td>\n",
       "      <td>0.907782</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.835087</td>\n",
       "      <td>0.907782</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>19</td>\n",
       "      <td>0.835087</td>\n",
       "      <td>0.907782</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>0.835087</td>\n",
       "      <td>0.907782</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>0.835087</td>\n",
       "      <td>0.907782</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>0.835087</td>\n",
       "      <td>0.907782</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank_test_score  mean_test_score  mean_train_score param_learning_rate  \\\n",
       "26                1         0.856159          0.956585                0.15   \n",
       "24                1         0.856159          0.956585                0.15   \n",
       "17                1         0.856159          0.956585                0.15   \n",
       "6                 1         0.856159          0.956585                0.15   \n",
       "7                 1         0.856159          0.956585                0.15   \n",
       "8                 1         0.856159          0.956585                0.15   \n",
       "16                1         0.856159          0.956585                0.15   \n",
       "15                1         0.856159          0.956585                0.15   \n",
       "25                1         0.856159          0.956585                0.15   \n",
       "23               10         0.854083          0.940772                 0.1   \n",
       "22               10         0.854083          0.940772                 0.1   \n",
       "21               10         0.854083          0.940772                 0.1   \n",
       "14               10         0.854083          0.940772                 0.1   \n",
       "13               10         0.854083          0.940772                 0.1   \n",
       "5                10         0.854083          0.940772                 0.1   \n",
       "4                10         0.854083          0.940772                 0.1   \n",
       "3                10         0.854083          0.940772                 0.1   \n",
       "12               10         0.854083          0.940772                 0.1   \n",
       "11               19         0.835087          0.907782                0.05   \n",
       "10               19         0.835087          0.907782                0.05   \n",
       "9                19         0.835087          0.907782                0.05   \n",
       "18               19         0.835087          0.907782                0.05   \n",
       "19               19         0.835087          0.907782                0.05   \n",
       "20               19         0.835087          0.907782                0.05   \n",
       "2                19         0.835087          0.907782                0.05   \n",
       "1                19         0.835087          0.907782                0.05   \n",
       "0                19         0.835087          0.907782                0.05   \n",
       "\n",
       "   param_njobs param_baseScore  \n",
       "26           6             0.7  \n",
       "24           2             0.7  \n",
       "17           6             0.5  \n",
       "6            2             0.3  \n",
       "7            4             0.3  \n",
       "8            6             0.3  \n",
       "16           4             0.5  \n",
       "15           2             0.5  \n",
       "25           4             0.7  \n",
       "23           6             0.7  \n",
       "22           4             0.7  \n",
       "21           2             0.7  \n",
       "14           6             0.5  \n",
       "13           4             0.5  \n",
       "5            6             0.3  \n",
       "4            4             0.3  \n",
       "3            2             0.3  \n",
       "12           2             0.5  \n",
       "11           6             0.5  \n",
       "10           4             0.5  \n",
       "9            2             0.5  \n",
       "18           2             0.7  \n",
       "19           4             0.7  \n",
       "20           6             0.7  \n",
       "2            6             0.3  \n",
       "1            4             0.3  \n",
       "0            2             0.3  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cv_results1 = pd.DataFrame(model_xgboost_hp.cv_results_)\n",
    "df_cv_results1 = df_cv_results1[['rank_test_score','mean_test_score', 'mean_train_score','param_learning_rate','param_njobs',\n",
    "                              'param_baseScore']]\n",
    "\n",
    "df_cv_results1.sort_values(by='rank_test_score', inplace=True)\n",
    "df_cv_results1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39ab7a80-6546-4db1-8823-6e0e5838924f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv_results1.to_csv(\"output/model1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d8f3a2-9bb5-4534-ae7f-fd1c7a278ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
